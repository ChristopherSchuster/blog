OpenStack Introduction for Ubuntu Part IV


<p>This is the fourth  Post about Open Stack Introduction. <a href="http://www.maigfrga.ntweb.co/openstack-introduction-ubuntu-part-i/">The first part of this post series
is about general concepts, basic configuration and Identity service installation </a>, 
<a href="http://www.maigfrga.ntweb.co/openstack-introduction-ubuntu-part-ii/"> the second part one continue with Image and Compute services.</a>, <a href="http://www.maigfrga.ntweb.co/introduccion-a-openstack-para-ubuntu-parte-iii/"> the third part is about about dashboard and block storage configuration.</a>.
This part is about Object Storage Service and Networking service.
<a href="http://docs.openstack.org/havana/install-guide/install/apt/content/">At this link a complete installation guide can be found.</a>
</p>


<h3>Add Object Storage</h3>

<h4>Object Storage service</h4>

<p>
The Object Storage service is a storage system for large amounts of unstructured data through a RESTful HTTP API.
It includes the following components:
</p>

<ul>
    <li>Proxy servers (swift-proxy-server). Accepts Object Storage API and raw HTTP requests to upload files, modify metadata, and create containers.</li>
    <li>Account servers (swift-account-server). Manage accounts defined with the Object Storage service  </li>
    <li>Container servers (swift-container-server). Manage a mapping of containers, or folders, within the Object Storage service.</li>
    <li>Object servers (swift-object-server). Manage actual objects, such as files, on the storage nodes.  </li>
    <li>Periodic process for general maintenance tasks (auditors, updaters, reapers) </li>
</ul>

<h4> Systems Requirements</h4>
<p>At this guide we won't think about this, but for a real production environment <a href="http://docs.openstack.org/havana/install-guide/install/apt/content/object-storage-system-requirements.html"> You need to study carefully the system requirements defined at this link. </a> 
</p>

<h4>Plan networking for Object Storage</h4>

<p>
 For this guide we'll only setup a mandatory public network and a mandatory storage network. 
 <a href="http://docs.openstack.org/havana/install-guide/install/apt/content/object-storage-network-planning.html"> Another options can be found at this link</a>
</p>

<h4>Example Object Storage installation architecture</h4>

<ul>
    <li>
        Node: A host machine that runs one or more OpenStack Object Storage services.
    </li>

    <li>
        Proxy node: Runs Proxy services.
    </li>

    <li>
        Storage node: Runs Account, Container, and Object services.
    </li>    

    <li>
    Ring: A set of mappings between OpenStack Object Storage data to physical devices.
    </li>

    <li>
    Replica: A copy of an object. By default, three copies are maintained in the cluster.
    </li>

    <li>
    Zone: A logically separate section of the cluster, related to independent failure characteristics.
    </li>
</ul>   

<p><strong>Note:</strong> for this guide  we will install one proxy node which runs the swift-proxy-server processes and three storage nodes 
    that run the swift-account-server, swift-container-server, and swift-object-server processes which control storage of the account databases, 
    the container databases, as well as the actual stored objects.
</p>

<p> Edit /etc/hosts in all nodes (controller, block1 , storage1...)

</p>

<pre>
    127.0.0.1       localhost
    192.168.0.10    controller
    192.168.0.11    compute1
    192.168.0.12    block1
    192.168.0.13    swift-proxy
    192.168.0.14    storage1
    192.168.0.15    storage2
    192.168.0.16    storage3
</pre>

<p>Edit /etc/hostname and set hostname to storage1
</p>

<p> Add Open Stack repositories</p>

<pre>
   # apt-get install python-software-properties
   # add-apt-repository cloud-archive:havana 
   # apt-get update && apt-get dist-upgrade
   # reboot
</pre>

<p>
Create a swift user that the Object Storage Service can use to authenticate with the Identity Service.
Execute the next commands in the controller node:
</p>

<pre>
   # keystone user-create --name=swift --pass=SWIFT_PASS \
  --email=swift@example.com
  # keystone user-role-add --user=swift --tenant=service --role=admin 

    +----------+----------------------------------+
    | Property |              Value               |
    +----------+----------------------------------+
    |  email   |        swift@example.com         |
    | enabled  |               True               |
    |    id    | b64f304b791d485ea960d8a0296bb63d |
    |   name   |              swift               |
    +----------+----------------------------------+

</pre>

<p>
   Create a service entry for the Object Storage Service: 
</p>

<pre>
   # keystone service-create --name=swift --type=object-store \
  --description="Object Storage Service" 

    +-------------+----------------------------------+
    |   Property  |              Value               |
    +-------------+----------------------------------+
    | description |      Object Storage Service      |
    |      id     | e54246ea9eb64d5ca002cbf5481dd5eb |
    |     name    |              swift               |
    |     type    |           object-store           |
    +-------------+----------------------------------+

</pre>

<p>
Specify an API endpoint for the Object Storage Service by using the returned service ID. 
</p>

<pre>
# keystone endpoint-create \
  --service-id=the_service_id_above \
  --publicurl='http://storage1:8080/v1/AUTH_%(tenant_id)s' \
  --internalurl='http://storage1:8080/v1/AUTH_%(tenant_id)s' \
  --adminurl=http://storage1:8080

    +-------------+----------------------------------------------+
    |   Property  |                    Value                     |
    +-------------+----------------------------------------------+
    |   adminurl  |            http://controller:8080            |
    |      id     |       e8f5a0654b7f4af6a9c2357250dd5c63       |
    | internalurl | http://controller:8080/v1/AUTH_%(tenant_id)s |
    |  publicurl  | http://controller:8080/v1/AUTH_%(tenant_id)s |
    |    region   |                  regionOne                   |
    |  service_id |       e54246ea9eb64d5ca002cbf5481dd5eb       |
    +-------------+----------------------------------------------+

</pre>

<p>
   Create the configuration directory on all swift nodes (In this guide is only one node): 
</p>

<pre>
   # mkdir -p /etc/swift 
</pre>

<p>
Create /etc/swift/swift.conf on all nodes:
</p>

<pre>
    [swift-hash]
    # random unique string that can never change (DO NOT LOSE)
    swift_hash_path_suffix = afLIeftgibit
</pre>

<p>
    <strong>Note:</strong> The suffix value in /etc/swift/swift.conf should be set to some random string of text to be used as a salt when hashing to determine mappings in the ring. This file must be the same on every node in the cluster! 
</p>

<p>Install Storage node packages:</p>

<pre>
   # apt-get install swift swift-account swift-container swift-object xfsprogs 
</pre>

<p>
For each device on the node that you want to use for storage, set up the XFS volume (/dev/sdb is used as an example). Use a single partition per drive. For example, in a server with 12 disks you may use one or two disks for the operating system which should not be touched in this step. The other 10 or 11 disks should be partitioned with a single partition, then formatted in XFS.
</p>

<pre>
    # fdisk /dev/sdb
    # mkfs.xfs /dev/sdb1
    # echo "/dev/sdb1 /srv/node/sdb1 xfs noatime,nodiratime,nobarrier,logbufs=8 0 0" >> /etc/fstab
    # mkdir -p /srv/node/sdb1
    # mount /srv/node/sdb1
    # chown -R swift:swift /srv/node
</pre>


<p>
    Create /etc/rsyncd.conf:
</p>

<pre>
    uid = swift
    gid = swift
    log file = /var/log/rsyncd.log
    pid file = /var/run/rsyncd.pid
    address = STORAGE_LOCAL_NET_IP
     
    [account]
    max connections = 2
    path = /srv/node/
    read only = false
    lock file = /var/lock/account.lock
     
    [container]
    max connections = 2
    path = /srv/node/
    read only = false
    lock file = /var/lock/container.lock
     
    [object]
    max connections = 2
    path = /srv/node/
    read only = false
    lock file = /var/lock/object.lock
</pre>

<p>
    Edit the following line in /etc/default/rsync:
</p>

<pre>
    RSYNC_ENABLE=true
</pre>

<p>
Start the rsync service:
</p>

<pre>
   # service rsync start 
   # mkdir -p /var/swift/recon
  # chown -R swift:swift /var/swift/recon

</pre>

<h4>Install and configure the proxy node</h4>

<p>
   The proxy server takes each request and looks up locations for the account, container, or object and routes the requests correctly. The proxy server also handles API requests. You enable account management by configuring it in the /etc/swift/proxy-server.conf file. 
</p>

<p>Install swift-proxy service:</p>

<pre>
   # apt-get install swift-proxy memcached python-keystoneclient python-swiftclient python-webob 
</pre>

<p>
Modify memcached to listen on the default interface on a local, non-public network. Edit this line in the /etc/memcached.conf file: 
change 
</p>

<pre>
   -l 127.0.0.1 
</pre>

<p> to:</p>

<pre>
   -l PROXY_LOCAL_NET_IP 
</pre>

<p>Restart the memcached service:</p>

<pre>
   # service memcached restart 
</pre>

<p>
Create /etc/swift/proxy-server.conf:
</p>

<pre>
   [DEFAULT]
    bind_port = 8080
    user = swift
     
    [pipeline:main]
    pipeline = healthcheck cache authtoken keystoneauth proxy-server
     
    [app:proxy-server]
    use = egg:swift#proxy
    allow_account_management = true
    account_autocreate = true
     
    [filter:keystoneauth]
    use = egg:swift#keystoneauth
    operator_roles = Member,admin,swiftoperator
     
    [filter:authtoken]
    paste.filter_factory = keystoneclient.middleware.auth_token:filter_factory
     
    # Delaying the auth decision is required to support token-less
    # usage for anonymous referrers ('.r:*').
    delay_auth_decision = true
     
    # cache directory for signing certificate
    signing_dir = /home/swift/keystone-signing
     
    # auth_* settings refer to the Keystone server
    auth_protocol = http
    auth_host = controller
    auth_port = 35357
     
    # the service tenant and swift username and password created in Keystone
    admin_tenant_name = service
    admin_user = swift
    admin_password = SWIFT_PASS
     
    [filter:cache]
    use = egg:swift#memcache
     
    [filter:catch_errors]
    use = egg:swift#catch_errors
     
    [filter:healthcheck]
    use = egg:swift#healthcheck 
</pre>


<p>
   Create the account, container, and object rings. The builder command creates a builder file with a few parameters. The parameter with the value of 18 represents 2 ^ 18th, the value that the partition is sized to. 
   Set this “partition power” value based on the total amount of storage you expect your entire ring to use. The value 3 represents the number of replicas of each object, with the last value being the number of hours to restrict moving a partition more than once. 
</p>

<pre>
    # cd /etc/swift
    # swift-ring-builder account.builder create 18 3 1
    # swift-ring-builder container.builder create 18 3 1
    # swift-ring-builder object.builder create 18 3 1 
</pre>

<p>
For every storage device on each node add entries to each ring:
</p>

<pre>
    # swift-ring-builder account.builder add zZONE-STORAGE_LOCAL_NET_IP:6002[RSTORAGE_REPLICATION_NET_IP:6005]/DEVICE 100
    # swift-ring-builder container.builder add zZONE-STORAGE_LOCAL_NET_IP_1:6001[RSTORAGE_REPLICATION_NET_IP:6004]/DEVICE 100
    # swift-ring-builder object.builder add zZONE-STORAGE_LOCAL_NET_IP_1:6000[RSTORAGE_REPLICATION_NET_IP:6003]/DEVICE 100
</pre>

<p>
<strong> Note: </strong> In this post we only have on storage device on one node and we don't have replication so wan ignore the optional STORAGE_REPLICATION_NET_IP parameter:

</p>


<p>
   For example, if a storage node has a partition in Zone 1 on IP 192.168.0.16 without replication network. The mount point of this partition is /srv/node/sdb1, and the path in /etc/rsyncd.conf is /srv/node/, the DEVICE would be sdb1 and the commands are: 
</p>

<pre>
    # swift-ring-builder account.builder add z1-192.168.0.16:6002/sdb1 100
    WARNING: No region specified for z1-192.168.0.16:6002/sdb1. Defaulting to region 1.
    Device d0r1z1-192.168.0.16:6002R192.168.0.16:6002/sdb1_"" with 100.0 weight got id 0

    #swift-ring-builder container.builder add z1-192.168.0.16:6002/sdb1 100
    WARNING: No region specified for z1-192.168.0.16:6002/sdb1. Defaulting to region 1.
    Device d0r1z1-192.168.0.16:6002R192.168.0.16:6002/sdb1_"" with 100.0 weight got id 0



    # swift-ring-builder object.builder add z1-192.168.0.16:6002/sdb1 100
    WARNING: No region specified for z1-192.168.0.16:6002/sdb1. Defaulting to region 1.
    Device d0r1z1-192.168.0.16:6002R192.168.0.16:6002/sdb1_"" with 100.0 weight got id 0
</pre>

<p>
Verify the ring contents for each ring:
</p>

<pre>
   # cd /etc/swift/

   # swift-ring-builder account.builder
   # swift-ring-builder container.builder
   # swift-ring-builder object.builder 

    account.builder, build version 1
    262144 partitions, 3.000000 replicas, 1 regions, 1 zones, 1 devices, 100.00 balance
    The minimum number of hours before a partition can be reassigned is 1
    Devices:    id  region  zone      ip address  port  replication ip  replication port      name weight partitions balance meta
                 0       1     1    192.168.0.16  6002    192.168.0.16              6002      sdb1 100.00          0 -100.00 

</pre>

<p>
   Rebalance the rings: 
</p>

<pre>
    # swift-ring-builder account.builder rebalance
    # swift-ring-builder container.builder rebalance
    # swift-ring-builder object.builder rebalance
</pre>

<p>
Copy the account.ring.gz, container.ring.gz, and object.ring.gz files to each of the Proxy and Storage nodes in /etc/swift.
</p>

<p>
    Make sure the swift user owns all configuration files:
</p>

<pre>
   # chown -R swift:swift /etc/swift 
</pre>


<p>Restart service: </p>
<pre>
    #service swift-proxy stop
    #service swift-proxy start 
</pre>

<p>
Start services on the storage nodes
</p>

<pre>
    # swift-init all start
</pre>

<h4> Verify the installation </h4>

<p>
You can run these commands from the proxy server or any server that has access to the Identity Service. 
</p>


<pre>
  #swift stat  
   Account: AUTH_fe13b472ad9e43e2aa8c71e7cc1c5f7c
Containers: 0
   Objects: 0
     Bytes: 0
Content-Type: text/plain; charset=utf-8
X-Timestamp: 1402842465.82440
X-Put-Timestamp: 1402842465.82440
    
</pre>


<p>
    Create and upload a test.txt file
</p>


<pre>
    $echo "this is a test" > test.txt
    $swift upload myfiles test.txt 
</pre>
